## 📊 Job Scraper Project
A Python-based project that scrapes job postings from RemoteOK, cleans the dataset, and performs exploratory analysis to uncover job market trends.

---
## 📂 Project Structure
**remoteok_jobs34.csv — Raw dataset generated from the scraper.**

**Web_Scraping_And_Analysis_Of_Job_Postings.ipynb — Script to scrape job listings (title, company, location, date, description) and store them in a CSV file.Jupyter Notebook for data cleaning and analysis.**

---

## 🔹 Features
-**Web Scraping**:

Extract job title, company, location, skills, posteddate, and description.
Built using BeautifulSoup for automated browsing.

-**Data Cleaning**:

Handle missing skills through dropping those rows and removing all of the duplicates.

-**Data Analysis**:

Location-based trends.

Remote vs On-site job share.

Top hiring companies.

Job posting frequency over time.

Top job titles.

Top demand skills.

Top job locations.

Top skills by city.

---
## 🛠 Technologies Used
```bash
Python 
BeautifulSoup
Pandas
Matplotlib / Seaborn
Jupyter Notebook
```
---
## 🚀 How to Run
1. Clone the repository:
```bash
git clone https://github.com/<your-username>/job-scraper-project.git
cd job-scraper-project
```
```bash
2. Run the Web_Scraping_And_Analysis_Of_Job_Postings.ipynb for data exploration.
```
---
## 📌 Insights
Some interesting findings:

Onsite work has a strong presence in the current job market.

Certain companies are posting significantly more jobs than others.

Posting frequency trends can be observed over time.

---
## 📄 License
This project is licensed under the MIT License.

---
## 👤 Author: Raahim Muzaffar Ishtiaq
🔗 GitHub: github.com/raahim27-hash/Job-Scraper-Project/

🤝 Special Thanks: Elevvo Pathways

---
