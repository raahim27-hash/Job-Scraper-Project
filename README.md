## ğŸ“Š Job Scraper Project
A Python-based project that scrapes job postings from RemoteOK, cleans the dataset, and performs exploratory analysis to uncover job market trends.

---
## ğŸ“‚ Project Structure
**remoteok_jobs34.csv â€” Raw dataset generated from the scraper.**

**Web_Scraping_And_Analysis_Of_Job_Postings.ipynb â€” Script to scrape job listings (title, company, location, date, description) and store them in a CSV file.Jupyter Notebook for data cleaning and analysis.**

---

## ğŸ”¹ Features
-**Web Scraping**:

Extract job title, company, location, skills, posteddate, and description.
Built using BeautifulSoup for automated browsing.

-**Data Cleaning**:

Handle missing skills through dropping those rows and removing all of the duplicates.

-**Data Analysis**:

Location-based trends.

Remote vs On-site job share.

Top hiring companies.

Job posting frequency over time.

Top job titles.

Top demand skills.

Top job locations.

Top skills by city.

---
## ğŸ›  Technologies Used
```bash
Python 
BeautifulSoup
Pandas
Matplotlib / Seaborn
Jupyter Notebook
```
---
## ğŸš€ How to Run
1. Clone the repository:
```bash
git clone https://github.com/<your-username>/job-scraper-project.git
cd job-scraper-project
```
```bash
2. Run the Web_Scraping_And_Analysis_Of_Job_Postings.ipynb for data exploration.
```
---
## ğŸ“Œ Insights
Some interesting findings:

Onsite work has a strong presence in the current job market.

Certain companies are posting significantly more jobs than others.

Posting frequency trends can be observed over time.

---
## ğŸ“„ License
This project is licensed under the MIT License.

---
## ğŸ‘¤ Author: Raahim Muzaffar Ishtiaq
ğŸ”— GitHub: github.com/raahim27-hash/Job-Scraper-Project/

ğŸ¤ Special Thanks: Elevvo Pathways

---
